{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "known_weather_data = {\n",
    "    'berlin': 20.0\n",
    "}\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Define function description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",                                              # the function's name\n",
    "    \"description\": \"Get the current weather for a given city or location\",    # what the function does\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the city or location to get the weather for\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_assistant.py already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('chat_assistant.py'):\n",
    "    !wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py -OutFile chat_assistant.py\n",
    "else:\n",
    "    print('chat_assistant.py already exists.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (1.97.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (3.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'get_weather',\n",
       "  'description': 'Get the current weather for a given city or location',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'city': {'type': 'string',\n",
       "     'description': 'The name of the city or location to get the weather for'}},\n",
       "   'required': ['city'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chat_assistant\n",
    "#from chat_assistant import Tools, ChatAssistant, ChatInterface\n",
    "import os\n",
    "\n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(get_weather, get_weather_tool)\n",
    "\n",
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()#api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a weatherman. Use the get_weather tool to answer questions about weather forecast.\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.38.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.11.0 (from gradio)\n",
      "  Downloading gradio_client-1.11.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub>=0.28.1 (from gradio)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting jinja2<4.0 (from gradio)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe<4.0,>=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting numpy<3.0,>=1.0 (from gradio)\n",
      "  Downloading numpy-2.3.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.11.0-cp311-cp311-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: packaging in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from gradio) (24.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.3.1-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<12.0,>=8.0 (from gradio)\n",
      "  Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from gradio) (2.11.7)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.12.3-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec (from gradio-client==1.11.0->gradio)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.11.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Collecting filelock (from huggingface-hub>=0.28.1->gradio)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting requests (from huggingface-hub>=0.28.1->gradio)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub>=0.28.1->gradio)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.28.1->gradio)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading gradio-5.38.0-py3-none-any.whl (59.6 MB)\n",
      "   ---------------------------------------- 0.0/59.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/59.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/59.6 MB 1.7 MB/s eta 0:00:36\n",
      "    --------------------------------------- 1.0/59.6 MB 2.1 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 1.6/59.6 MB 2.2 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 2.1/59.6 MB 2.3 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 2.9/59.6 MB 2.5 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 3.7/59.6 MB 2.7 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 4.5/59.6 MB 2.9 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 5.2/59.6 MB 3.1 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 6.0/59.6 MB 3.1 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 6.8/59.6 MB 3.1 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 7.9/59.6 MB 3.3 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 8.9/59.6 MB 3.4 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 10.0/59.6 MB 3.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 11.0/59.6 MB 3.6 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 12.1/59.6 MB 3.8 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 13.1/59.6 MB 3.8 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 14.7/59.6 MB 4.0 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 16.0/59.6 MB 4.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 16.3/59.6 MB 4.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 17.8/59.6 MB 4.1 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 18.9/59.6 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 20.2/59.6 MB 4.3 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 21.2/59.6 MB 4.3 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 22.0/59.6 MB 4.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 23.6/59.6 MB 4.4 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 24.6/59.6 MB 4.5 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 25.7/59.6 MB 4.5 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 27.0/59.6 MB 4.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 28.3/59.6 MB 4.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 29.4/59.6 MB 4.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 29.9/59.6 MB 4.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 30.9/59.6 MB 4.6 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 31.7/59.6 MB 4.6 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 33.0/59.6 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 34.1/59.6 MB 4.6 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 35.4/59.6 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 36.2/59.6 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 37.5/59.6 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 38.0/59.6 MB 4.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 39.3/59.6 MB 4.7 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 40.4/59.6 MB 4.7 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 41.4/59.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 42.2/59.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 43.3/59.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 44.0/59.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 45.4/59.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 46.1/59.6 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 46.1/59.6 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 46.7/59.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 47.4/59.6 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 48.8/59.6 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 50.1/59.6 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 51.4/59.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 52.4/59.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 53.0/59.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 53.5/59.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 54.5/59.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 55.6/59.6 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 56.9/59.6 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 57.9/59.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  59.2/59.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 59.6/59.6 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.11.0-py3-none-any.whl (324 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading numpy-2.3.1-cp311-cp311-win_amd64.whl (13.0 MB)\n",
      "   ---------------------------------------- 0.0/13.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.0 MB 5.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/13.0 MB 4.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.6/13.0 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/13.0 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/13.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.5/13.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/13.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/13.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.4/13.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.7/13.0 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/13.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/13.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/13.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.0/13.0 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading orjson-3.11.0-cp311-cp311-win_amd64.whl (129 kB)\n",
      "Downloading pandas-2.3.1-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.3 MB 4.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.1/11.3 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.3 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.3 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.0/11.3 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.3 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/7.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.8/7.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.9/7.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.5/7.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/7.0 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.47.1-py3-none-any.whl (72 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
      "Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl (357 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading ruff-0.12.3-py3-none-win_amd64.whl (11.7 MB)\n",
      "   ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.7 MB 5.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/11.7 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/11.7 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.7 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.7 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/11.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.7/11.7 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: pytz, pydub, brotli, websockets, urllib3, tzdata, tomlkit, shellingham, semantic-version, ruff, pyyaml, python-multipart, pillow, orjson, numpy, mdurl, markupsafe, groovy, fsspec, filelock, ffmpy, click, charset_normalizer, aiofiles, uvicorn, starlette, requests, pandas, markdown-it-py, jinja2, safehttpx, rich, huggingface-hub, fastapi, typer, gradio-client, gradio\n",
      "\n",
      "   ----------------------------------------  0/37 [pytz]\n",
      "   - --------------------------------------  1/37 [pydub]\n",
      "   --- ------------------------------------  3/37 [websockets]\n",
      "   --- ------------------------------------  3/37 [websockets]\n",
      "   --- ------------------------------------  3/37 [websockets]\n",
      "   --- ------------------------------------  3/37 [websockets]\n",
      "   ---- -----------------------------------  4/37 [urllib3]\n",
      "   ---- -----------------------------------  4/37 [urllib3]\n",
      "   ---- -----------------------------------  4/37 [urllib3]\n",
      "   ----- ----------------------------------  5/37 [tzdata]\n",
      "   ----- ----------------------------------  5/37 [tzdata]\n",
      "   ------ ---------------------------------  6/37 [tomlkit]\n",
      "   --------- ------------------------------  9/37 [ruff]\n",
      "   --------- ------------------------------  9/37 [ruff]\n",
      "   --------- ------------------------------  9/37 [ruff]\n",
      "   ---------- ----------------------------- 10/37 [pyyaml]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   ------------ --------------------------- 12/37 [pillow]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   --------------- ------------------------ 14/37 [numpy]\n",
      "   ---------------- ----------------------- 15/37 [mdurl]\n",
      "   ------------------- -------------------- 18/37 [fsspec]\n",
      "   ------------------- -------------------- 18/37 [fsspec]\n",
      "   ------------------- -------------------- 18/37 [fsspec]\n",
      "   ------------------- -------------------- 18/37 [fsspec]\n",
      "   -------------------- ------------------- 19/37 [filelock]\n",
      "   ---------------------- ----------------- 21/37 [click]\n",
      "   ---------------------- ----------------- 21/37 [click]\n",
      "   ----------------------- ---------------- 22/37 [charset_normalizer]\n",
      "   ------------------------- -------------- 24/37 [uvicorn]\n",
      "   ------------------------- -------------- 24/37 [uvicorn]\n",
      "   ------------------------- -------------- 24/37 [uvicorn]\n",
      "   --------------------------- ------------ 25/37 [starlette]\n",
      "   --------------------------- ------------ 25/37 [starlette]\n",
      "   --------------------------- ------------ 25/37 [starlette]\n",
      "   ---------------------------- ----------- 26/37 [requests]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ----------------------------- ---------- 27/37 [pandas]\n",
      "   ------------------------------ --------- 28/37 [markdown-it-py]\n",
      "   ------------------------------ --------- 28/37 [markdown-it-py]\n",
      "   ------------------------------ --------- 28/37 [markdown-it-py]\n",
      "   ------------------------------ --------- 28/37 [markdown-it-py]\n",
      "   ------------------------------- -------- 29/37 [jinja2]\n",
      "   ------------------------------- -------- 29/37 [jinja2]\n",
      "   --------------------------------- ------ 31/37 [rich]\n",
      "   --------------------------------- ------ 31/37 [rich]\n",
      "   --------------------------------- ------ 31/37 [rich]\n",
      "   --------------------------------- ------ 31/37 [rich]\n",
      "   --------------------------------- ------ 31/37 [rich]\n",
      "   --------------------------------- ------ 31/37 [rich]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ---------------------------------- ----- 32/37 [huggingface-hub]\n",
      "   ----------------------------------- ---- 33/37 [fastapi]\n",
      "   ----------------------------------- ---- 33/37 [fastapi]\n",
      "   ----------------------------------- ---- 33/37 [fastapi]\n",
      "   ------------------------------------ --- 34/37 [typer]\n",
      "   ------------------------------------- -- 35/37 [gradio-client]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   -------------------------------------- - 36/37 [gradio]\n",
      "   ---------------------------------------- 37/37 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 brotli-1.1.0 charset_normalizer-3.4.2 click-8.2.1 fastapi-0.116.1 ffmpy-0.6.0 filelock-3.18.0 fsspec-2025.7.0 gradio-5.38.0 gradio-client-1.11.0 groovy-0.1.2 huggingface-hub-0.33.4 jinja2-3.1.6 markdown-it-py-3.0.0 markupsafe-3.0.2 mdurl-0.1.2 numpy-2.3.1 orjson-3.11.0 pandas-2.3.1 pillow-11.3.0 pydub-0.25.1 python-multipart-0.0.20 pytz-2025.2 pyyaml-6.0.2 requests-2.32.4 rich-14.0.0 ruff-0.12.3 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.47.1 tomlkit-0.13.3 typer-0.16.0 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.35.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Tunis\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Tunis\"}', call_id='call_WwGayDOvfi9nZDQERilyxrE3', name='get_weather', type='function_call', id='fc_6878d2e92f18819ea0ed7ecd61df6e80089200f8696141c2', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>-3.7</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>It seems there was an issue retrieving the weather data for Tunis. Please give me a moment to try again.</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Tunis\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Tunis\"}', call_id='call_XAyDAQVZm3OcpbAortTUkW6z', name='get_weather', type='function_call', id='fc_6878d2ebcf30819e9d2c63191e4e4e21089200f8696141c2', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>4.7</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Berlin\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Berlin\"}', call_id='call_gdO4pFe8EnZaphDqnN19zNN9', name='get_weather', type='function_call', id='fc_6878d303ece4819eb335cb784dcc6d05089200f8696141c2', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>20.0</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The current weather in Berlin is 20°C. If you need more specific details or a forecast, let me know!</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weather(city: str, temp: float) -> None:\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp # Update the temperature for a given city\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"set_weather\",\n",
    "    \"description\": \"Add or update the temperature for a city or location\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the city to set the temperature for\"\n",
    "            },\n",
    "            \"temp\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The current temperature in Celsius for the city\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\", \"temp\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.add_tool(set_weather, set_weather_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'get_weather',\n",
       "  'description': 'Get the current weather for a given city or location',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'city': {'type': 'string',\n",
       "     'description': 'The name of the city or location to get the weather for'}},\n",
       "   'required': ['city'],\n",
       "   'additionalProperties': False}},\n",
       " {'type': 'function',\n",
       "  'name': 'set_weather',\n",
       "  'description': 'Add or update the temperature for a city or location',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'city': {'type': 'string',\n",
       "     'description': 'The name of the city to set the temperature for'},\n",
       "    'temp': {'type': 'number',\n",
       "     'description': 'The current temperature in Celsius for the city'}},\n",
       "   'required': ['city', 'temp'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastmcp\n",
      "  Downloading fastmcp-2.10.5-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting authlib>=1.5.2 (from fastmcp)\n",
      "  Downloading authlib-1.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cyclopts>=3.0.0 (from fastmcp)\n",
      "  Downloading cyclopts-3.22.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting exceptiongroup>=1.2.2 (from fastmcp)\n",
      "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: httpx>=0.28.1 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from fastmcp) (0.28.1)\n",
      "Collecting mcp>=1.10.0 (from fastmcp)\n",
      "  Downloading mcp-1.11.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting openapi-pydantic>=0.5.1 (from fastmcp)\n",
      "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic>=2.11.7 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic[email]>=2.11.7->fastmcp) (2.11.7)\n",
      "Collecting pyperclip>=1.9.0 (from fastmcp)\n",
      "  Downloading pyperclip-1.9.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-dotenv>=1.1.0 (from fastmcp)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: rich>=13.9.4 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from fastmcp) (14.0.0)\n",
      "Collecting cryptography (from authlib>=1.5.2->fastmcp)\n",
      "  Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting attrs>=23.1.0 (from cyclopts>=3.0.0->fastmcp)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting docstring-parser>=0.15 (from cyclopts>=3.0.0->fastmcp)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp)\n",
      "  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting docutils (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp)\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from exceptiongroup>=1.2.2->fastmcp) (4.12.2)\n",
      "Requirement already satisfied: anyio in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx>=0.28.1->fastmcp) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx>=0.28.1->fastmcp) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx>=0.28.1->fastmcp) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpx>=0.28.1->fastmcp) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp) (0.16.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp>=1.10.0->fastmcp)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting jsonschema>=4.20.0 (from mcp>=1.10.0->fastmcp)\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp>=1.10.0->fastmcp)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from mcp>=1.10.0->fastmcp) (0.0.20)\n",
      "Collecting pywin32>=310 (from mcp>=1.10.0->fastmcp)\n",
      "  Downloading pywin32-311-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp>=1.10.0->fastmcp)\n",
      "  Downloading sse_starlette-2.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from mcp>=1.10.0->fastmcp) (0.47.1)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from mcp>=1.10.0->fastmcp) (0.35.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from anyio->httpx>=0.28.1->fastmcp) (1.3.1)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.20.0->mcp>=1.10.0->fastmcp)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp>=1.10.0->fastmcp)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.20.0->mcp>=1.10.0->fastmcp)\n",
      "  Downloading rpds_py-0.26.0-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from rich>=13.9.4->fastmcp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from rich>=13.9.4->fastmcp) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp) (0.1.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from uvicorn>=0.23.1->mcp>=1.10.0->fastmcp) (8.2.1)\n",
      "Requirement already satisfied: colorama in c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\lib\\site-packages (from click>=7.0->uvicorn>=0.23.1->mcp>=1.10.0->fastmcp) (0.4.6)\n",
      "Collecting cffi>=1.14 (from cryptography->authlib>=1.5.2->fastmcp)\n",
      "  Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography->authlib>=1.5.2->fastmcp)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading fastmcp-2.10.5-py3-none-any.whl (201 kB)\n",
      "Downloading authlib-1.6.0-py2.py3-none-any.whl (239 kB)\n",
      "Downloading cyclopts-3.22.2-py3-none-any.whl (84 kB)\n",
      "Downloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Downloading mcp-1.11.0-py3-none-any.whl (155 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading pywin32-311-cp311-cp311-win_amd64.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.5 MB 4.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.3/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/9.5 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.4/9.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.2/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.5/9.5 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.3/9.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.3/9.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.26.0-cp311-cp311-win_amd64.whl (231 kB)\n",
      "Downloading sse_starlette-2.4.1-py3-none-any.whl (10 kB)\n",
      "Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.0/3.4 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.1/3.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.1/3.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl (181 kB)\n",
      "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "   ---------------------------------------- 0.0/587.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 587.4/587.4 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.9.0-py3-none-any.whl size=11117 sha256=ee9321306455a43912e878041f86a420c99a9e4ed9818ee354c07675ca43ade6\n",
      "  Stored in directory: c:\\users\\msi\\appdata\\local\\pip\\cache\\wheels\\e8\\e7\\56\\591cb88ba1783b38c40d584026e766aac9c3a048e34128ce8b\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pywin32, pyperclip, rpds-py, python-dotenv, pycparser, httpx-sse, exceptiongroup, docutils, docstring-parser, dnspython, attrs, sse-starlette, referencing, email-validator, cffi, rich-rst, pydantic-settings, openapi-pydantic, jsonschema-specifications, cryptography, jsonschema, cyclopts, authlib, mcp, fastmcp\n",
      "\n",
      "  Attempting uninstall: pywin32\n",
      "\n",
      "    Found existing installation: pywin32 308\n",
      "\n",
      "    Uninstalling pywin32-308:\n",
      "\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "      Successfully uninstalled pywin32-308\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ----------------------------------------  0/25 [pywin32]\n",
      "   ---- -----------------------------------  3/25 [python-dotenv]\n",
      "   ------ ---------------------------------  4/25 [pycparser]\n",
      "   ------ ---------------------------------  4/25 [pycparser]\n",
      "   -------- -------------------------------  5/25 [httpx-sse]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ----------- ----------------------------  7/25 [docutils]\n",
      "   ------------ ---------------------------  8/25 [docstring-parser]\n",
      "   ------------ ---------------------------  8/25 [docstring-parser]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   -------------- -------------------------  9/25 [dnspython]\n",
      "   ---------------- ----------------------- 10/25 [attrs]\n",
      "   ----------------- ---------------------- 11/25 [sse-starlette]\n",
      "   ------------------- -------------------- 12/25 [referencing]\n",
      "   -------------------- ------------------- 13/25 [email-validator]\n",
      "   ---------------------- ----------------- 14/25 [cffi]\n",
      "   ------------------------- -------------- 16/25 [pydantic-settings]\n",
      "   ------------------------- -------------- 16/25 [pydantic-settings]\n",
      "   --------------------------- ------------ 17/25 [openapi-pydantic]\n",
      "   --------------------------- ------------ 17/25 [openapi-pydantic]\n",
      "   --------------------------- ------------ 17/25 [openapi-pydantic]\n",
      "   --------------------------- ------------ 17/25 [openapi-pydantic]\n",
      "   ------------------------------ --------- 19/25 [cryptography]\n",
      "   ------------------------------ --------- 19/25 [cryptography]\n",
      "   ------------------------------ --------- 19/25 [cryptography]\n",
      "   ------------------------------ --------- 19/25 [cryptography]\n",
      "   ------------------------------ --------- 19/25 [cryptography]\n",
      "   -------------------------------- ------- 20/25 [jsonschema]\n",
      "   -------------------------------- ------- 20/25 [jsonschema]\n",
      "   -------------------------------- ------- 20/25 [jsonschema]\n",
      "   --------------------------------- ------ 21/25 [cyclopts]\n",
      "   --------------------------------- ------ 21/25 [cyclopts]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ----------------------------------- ---- 22/25 [authlib]\n",
      "   ------------------------------------ --- 23/25 [mcp]\n",
      "   ------------------------------------ --- 23/25 [mcp]\n",
      "   ------------------------------------ --- 23/25 [mcp]\n",
      "   ------------------------------------ --- 23/25 [mcp]\n",
      "   ------------------------------------ --- 23/25 [mcp]\n",
      "   ------------------------------------ --- 23/25 [mcp]\n",
      "   -------------------------------------- - 24/25 [fastmcp]\n",
      "   -------------------------------------- - 24/25 [fastmcp]\n",
      "   -------------------------------------- - 24/25 [fastmcp]\n",
      "   -------------------------------------- - 24/25 [fastmcp]\n",
      "   -------------------------------------- - 24/25 [fastmcp]\n",
      "   -------------------------------------- - 24/25 [fastmcp]\n",
      "   ---------------------------------------- 25/25 [fastmcp]\n",
      "\n",
      "Successfully installed attrs-25.3.0 authlib-1.6.0 cffi-1.17.1 cryptography-45.0.5 cyclopts-3.22.2 dnspython-2.7.0 docstring-parser-0.16 docutils-0.21.2 email-validator-2.2.0 exceptiongroup-1.3.0 fastmcp-2.10.5 httpx-sse-0.4.1 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 mcp-1.11.0 openapi-pydantic-0.5.1 pycparser-2.22 pydantic-settings-2.10.1 pyperclip-1.9.0 python-dotenv-1.1.1 pywin32-311 referencing-0.36.2 rich-rst-1.3.1 rpds-py-0.26.0 sse-starlette-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'pyperclip' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyperclip'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "%pip install fastmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: fastmcp\n",
      "Version: 2.10.5\n",
      "Summary: The fast, Pythonic way to build MCP servers and clients.\n",
      "Home-page: https://gofastmcp.com\n",
      "Author: Jeremiah Lowin\n",
      "Author-email: \n",
      "License-Expression: Apache-2.0\n",
      "Location: c:\\tools\\miniconda3\\envs\\llm-zoomcamp\\Lib\\site-packages\n",
      "Requires: authlib, cyclopts, exceptiongroup, httpx, mcp, openapi-pydantic, pydantic, pyperclip, python-dotenv, rich\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show fastmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "# FastMCP is a Python library for building multi-agent conversational platforms (MCPs).\n",
    "# It allows you to create, manage, and orchestrate multiple AI agents that can interact with each other and users in real time.\n",
    "# FastMCP provides tools for agent communication, memory, and workflow management, making it easier to develop complex conversational systems.\n",
    "mcp = FastMCP(\"Demo 🚀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mcp.tool # Registers get_weather as a callable tool for agents.\n",
    "def get_weather(city: str) -> float:\n",
    "    \"\"\"Get the current weather for a given city or location.\"\"\"\n",
    "\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mcp.tool # Registers set_weather as a callable tool for agents.\n",
    "def set_weather(city: str, temp: float) -> None:\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp # Update the temperature for a given city\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (4.53.2)\n",
      "Requirement already satisfied: accelerate in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: filelock in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: colorama in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (0.33.4)\n",
      "Requirement already satisfied: filelock in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from huggingface_hub) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from huggingface_hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from huggingface_hub) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from requests->huggingface_hub) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\datatalksclub\\llm-zoomcamp\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "True\n",
      "NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print: True\n",
    "print(torch.cuda.get_device_name(0))  # Should print your GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138bb62604dc4fe1ad7e963fd1038e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682a07e1e85e4558afccaee28626e1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 157.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_id)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or torch.float16\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# automatically uses your GPU\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Example of how to use the tool with the pipeline\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# The pipeline API does not natively support function-calling yet,\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# but you can pass the tools to the model.generate() call if you use the raw model.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# For demonstration, we show how to pass the tools in the pipeline call (if supported in future versions).\u001b[39;00m\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# If using the pipeline directly, you can pass the tools argument if supported:\u001b[39;00m\n\u001b[32m     55\u001b[39m pipe = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer, device_map=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, tools=mistral_tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\DataTalksClub\\llm-zoomcamp\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\DataTalksClub\\llm-zoomcamp\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:311\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    313\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\DataTalksClub\\llm-zoomcamp\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4839\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4830\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4832\u001b[39m     (\n\u001b[32m   4833\u001b[39m         model,\n\u001b[32m   4834\u001b[39m         missing_keys,\n\u001b[32m   4835\u001b[39m         unexpected_keys,\n\u001b[32m   4836\u001b[39m         mismatched_keys,\n\u001b[32m   4837\u001b[39m         offload_index,\n\u001b[32m   4838\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4839\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4845\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4848\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4855\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4857\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4858\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\DataTalksClub\\llm-zoomcamp\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5302\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5299\u001b[39m         args_list = logging.tqdm(args_list, desc=\u001b[33m\"\u001b[39m\u001b[33mLoading checkpoint shards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5301\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[32m-> \u001b[39m\u001b[32m5302\u001b[39m         _error_msgs, disk_offload_index, cpu_offload_index = \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5303\u001b[39m         error_msgs += _error_msgs\n\u001b[32m   5305\u001b[39m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\DataTalksClub\\llm-zoomcamp\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:933\u001b[39m, in \u001b[36mload_shard_file\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\DataTalksClub\\llm-zoomcamp\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\DataTalksClub\\llm-zoomcamp\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:845\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    842\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled():\n\u001b[32m    843\u001b[39m         param_device = \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m     _load_parameter_into_model(model, param_name, \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    848\u001b[39m     hf_quantizer.create_quantized_param(\n\u001b[32m    849\u001b[39m         model, param, param_name, param_device, state_dict, unexpected_keys\n\u001b[32m    850\u001b[39m     )\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 22.26 GiB is allocated by PyTorch, and 157.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",  # or torch.float16\n",
    "    device_map=\"cuda\"    # automatically uses your GPU\n",
    ")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Define the function to be used as a tool\n",
    "def get_weather_tool(city: str) -> str:\n",
    "    # Dummy implementation for demonstration\n",
    "    # In a real scenario, you would call a weather API here\n",
    "    return f\"The weather in {city} is sunny and 25°C.\"\n",
    "\n",
    "# Mistral function-calling tool definition (see https://docs.mistral.ai/capabilities/function_calling/)\n",
    "mistral_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather_tool\",\n",
    "            \"description\": \"Get the current weather for a given city.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the city to get the weather for.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",  # or torch.float16\n",
    "    device_map=\"cuda\"    # automatically uses your GPU\n",
    ")\n",
    "\n",
    "# Example of how to use the tool with the pipeline\n",
    "# The pipeline API does not natively support function-calling yet,\n",
    "# but you can pass the tools to the model.generate() call if you use the raw model.\n",
    "# For demonstration, we show how to pass the tools in the pipeline call (if supported in future versions).\n",
    "\n",
    "# If using the pipeline directly, you can pass the tools argument if supported:\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"cuda\", tools=mistral_tools)\n",
    "\n",
    "# For now, we just show the tool definition and function.\n",
    "\n",
    "#pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"cuda\")\n",
    "\n",
    "prompt = \"What's the weather like in Berlin today?\"\n",
    "result = pipe(prompt, max_new_tokens=100, do_sample=True, temperature=0.7)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a ChatAssistant that uses the local pipeline\n",
    "class LocalChatAssistant:\n",
    "    def __init__(self, tools, developer_prompt, chat_interface, local_pipe):\n",
    "        self.tools = tools\n",
    "        self.developer_prompt = developer_prompt\n",
    "        self.chat_interface = chat_interface\n",
    "        self.local_pipe = local_pipe\n",
    "\n",
    "    def gpt(self, chat_messages):\n",
    "        # Convert chat_messages (list of dicts) to a single prompt string\n",
    "        prompt = ''\n",
    "        for msg in chat_messages:\n",
    "            if msg['role'] == 'developer':\n",
    "                prompt += f'System: {msg[\"content\"]}\\n'\n",
    "            elif msg['role'] == 'user':\n",
    "                prompt += f'User: {msg[\"content\"]}\\n'\n",
    "            else:\n",
    "                prompt += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n",
    "        prompt += 'Assistant:'\n",
    "        # Generate response\n",
    "        result = self.local_pipe(prompt, max_new_tokens=200, do_sample=True, temperature=0.7)\n",
    "        # Simulate OpenAI's response object for compatibility\n",
    "        class Entry:\n",
    "            def __init__(self, text):\n",
    "                self.type = 'message'\n",
    "                self.content = [type('Obj', (), {'text': text})()]\n",
    "        return type('Response', (), {'output': [Entry(result[0]['generated_text'][len(prompt):].strip())]})()\n",
    "\n",
    "    async def run(self):\n",
    "        chat_messages = [\n",
    "            {'role': 'developer', 'content': self.developer_prompt},\n",
    "        ]\n",
    "        while True:\n",
    "            question = await self.chat_interface.input()\n",
    "            if question is None:\n",
    "                question = ''\n",
    "            if question.strip().lower() == 'stop':\n",
    "                self.chat_interface.display('Chat ended.')\n",
    "                break\n",
    "            message = {'role': 'user', 'content': question}\n",
    "            chat_messages.append(message)\n",
    "            while True:\n",
    "                response = self.gpt(chat_messages)\n",
    "                has_messages = False\n",
    "                for entry in response.output:\n",
    "                    chat_messages.append(entry)\n",
    "                    if entry.type == 'function_call':\n",
    "                        result = self.tools.function_call(entry)\n",
    "                        chat_messages.append(result)\n",
    "                        self.chat_interface.display_function_call(entry, result)\n",
    "                    elif entry.type == 'message':\n",
    "                        self.chat_interface.display_response(entry)\n",
    "                        has_messages = True\n",
    "                if has_messages:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\AppData\\Local\\Temp\\ipykernel_21480\\1953951497.py:20: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  self.input_box.on_submit(self._on_send)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4705db36aa0432ca234c72d63ea26d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='You:', placeholder='Type your question'), Button(description='Send'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chat_assistant\n",
    "from chat_assistant import Tools, ChatAssistant, ChatInterface\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "tools = Tools()\n",
    "tools.add_tool(get_weather, get_weather_tool)\n",
    "\n",
    "\n",
    "interface = WidgetChatInterface()\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a helpful weather bot. Use the get_weather tool to answer questions about weather.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Instantiate and run the local chat assistant\n",
    "chat = LocalChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=interface,\n",
    "    local_pipe=pipe\n",
    ")\n",
    "\n",
    "\n",
    "await chat.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\AppData\\Local\\Temp\\ipykernel_1184\\1953951497.py:20: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  self.input_box.on_submit(self._on_send)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae11c1a0d5494a12a9f82a896dfc0ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='You:', placeholder='Type your question'), Button(description='Send'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<coroutine object ChatAssistant.run at 0x0000027B70183BC0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chat_assistant\n",
    "from chat_assistant import Tools, ChatAssistant, ChatInterface\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "tools = Tools()\n",
    "tools.add_tool(get_weather, get_weather_tool)\n",
    "\n",
    "interface = WidgetChatInterface()\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a helpful weather bot. Use the get_weather tool to answer questions about weather.\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "chat = ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=interface,\n",
    "    client=client\n",
    ")\n",
    "chat.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
